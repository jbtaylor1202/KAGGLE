write.csv(x = topTweeter,file = "topTweeter.csv")
topRetweeter<-tweetDF%>%
group_by(screenName)%>%
summarise(totalretweets=sum(retweetCount))%>%
arrange(desc(totalretweets))
write.csv(x = topRetweeter,file = "topRetweeter.csv")
View(topRetweeter)
View(topRetweeter)
View(topTweeter)
library(dplyr)
tweetMaster<-file.choose
tweetMaster<-file.choose()
library(dplyr)
tweetMaster<-file.choose()
tweetData<-read.csv(tweetMaster)
View(tweetData)
library(dplyr)
library(tidyr)
topTweeter<-tweetDF%>%
group_by(screenName)%>%
summarise(count=n())%>%
arrange(desc(count))
write.csv(x = topTweeter,file = "topTweeter.csv")
topRetweeter<-tweetDF%>%
group_by(screenName)%>%
summarise(totalretweets=sum(retweetCount))%>%
arrange(desc(totalretweets))
write.csv(x = topRetweeter,file = "topRetweeter.csv")
topTweeter<-tweetData%>%
group_by(screenName)%>%
summarise(count=n())%>%
arrange(desc(count))
write.csv(x = topTweeter,file = "topTweeter.csv")
View(topTweeter)
View(tweetData)
tweetByDayDF<-tweetData
tweetByDay<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetByDay.csv")
View(tweetByDayDF)
View(tweetByDay)
View(tweetData)
tweetMaster<-file.choose()
tweetData<-read.csv(tweetMaster)
library(dplyr)
library(tidyr)
topTweeter<-tweetData%>%
group_by(screenName)%>%
summarise(count=n())%>%
arrange(desc(count))
write.csv(x = topTweeter,file = "topTweeter.csv")
View(topTweeter)
topRetweeter<-tweetData%>%
group_by(screenName)%>%
summarise(totalretweets=sum(retweetCount))%>%
arrange(desc(totalretweets))
write.csv(x = topRetweeter,file = "topRetweeter.csv")
tweetByDayDF<-tweetData
tweetByDay<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetByDay.csv")
library(ggplot2)
plotData<-read.csv("tweetByDay.csv")
plotData<-select(plotData,tweetDate,dayCount)
ggplot(data = plotData, aes(x = tweetDate, y=dayCount))+geom_bar(stat = "identity")
View(plotData)
View(tweetData)
View(topTweeter)
View(topTweeter)
View(tweetByDay)
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet='True')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetNOTRETWEETByDay.csv")
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet='TRUE')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet=='TRUE')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
View(tweetByDayTWEETnotRETWEET)
View(tweetByDayDF)
write.csv(x = tweetByDay,file = "tweetNOTRETWEETByDay.csv")
library(ggplot2)
plotData<-read.csv("tweetNOTRETWEETByDay.csv")
plotData<-select(plotData,tweetDate,dayCount)
ggplot(data = plotData, aes(x = tweetDate, y=dayCount))+geom_bar(stat = "identity")
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet=='TRUE')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetNOTRETWEETByDay.csv")
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet=='TRUE')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDayTWEETnotRETWEET,file = "tweetNOTRETWEETByDay.csv")
library(ggplot2)
plotData<-read.csv("tweetNOTRETWEETByDay.csv")
plotData<-select(plotData,tweetDate,dayCount)
ggplot(data = plotData, aes(x = tweetDate, y=dayCount))+geom_bar(stat = "identity")
library(twitteR)
#http://thinktostart.com/twitter-authentification-with-r/
#See https://apps.twitter.com/
consumerKey = "nD7NY6kqO8Fi3w48xJdBG9aD1"
consumerSecret = "YX6kBnn1CCbeDM2FQick78FAPmcvlKvUPjhgDNHoB3NTAl88X5"
accessToken = "532587577-dpIxDgmOCamsGApioe9BRDmrCVKDzus7ANPWgmT5"
accessSecret = "1au0kxES6SMId4SyfgK24abybVkNF5GF9saqnm84PC5ej"
options(httr_oauth_cache=TRUE) # skip question appearing on console
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
tweets<-searchTwitter("#DiscoverYourPower",n = 500)
tweetDF<-twListToDF(tweets)
currentDate<-Sys.Date()
csvFileName <- paste("tweets ",currentDate,".csv",sep="")
write.csv(x = tweetDF,file = csvFileName)
tweetMaster<-file.choose()
tweetData<-read.csv(tweetMaster)
library(dplyr)
library(tidyr)
topTweeter<-tweetData%>%
group_by(screenName)%>%
summarise(count=n())%>%
arrange(desc(count))
write.csv(x = topTweeter,file = "topTweeter.csv")
topRetweeter<-tweetData%>%
group_by(screenName)%>%
summarise(totalretweets=sum(retweetCount))%>%
arrange(desc(totalretweets))
write.csv(x = topRetweeter,file = "topRetweeter.csv")
View(topRetweeter)
View(topTweeter)
tweetByDayDF<-tweetData
tweetByDay<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetByDay.csv")
View(tweetByDay)
library(twitteR)
#http://thinktostart.com/twitter-authentification-with-r/
#See https://apps.twitter.com/
consumerKey = "nD7NY6kqO8Fi3w48xJdBG9aD1"
consumerSecret = "YX6kBnn1CCbeDM2FQick78FAPmcvlKvUPjhgDNHoB3NTAl88X5"
accessToken = "532587577-dpIxDgmOCamsGApioe9BRDmrCVKDzus7ANPWgmT5"
accessSecret = "1au0kxES6SMId4SyfgK24abybVkNF5GF9saqnm84PC5ej"
options(httr_oauth_cache=TRUE) # skip question appearing on console
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
tweets<-searchTwitter("#DiscoverYourPower",n = 500)
tweetDF<-twListToDF(tweets)
currentDate<-Sys.Date()
csvFileName <- paste("tweets ",currentDate,".csv",sep="")
write.csv(x = tweetDF,file = csvFileName)
View(tweetDF)
getwd()
library(twitteR)
#http://thinktostart.com/twitter-authentification-with-r/
#See https://apps.twitter.com/
consumerKey = "nD7NY6kqO8Fi3w48xJdBG9aD1"
consumerSecret = "YX6kBnn1CCbeDM2FQick78FAPmcvlKvUPjhgDNHoB3NTAl88X5"
accessToken = "532587577-dpIxDgmOCamsGApioe9BRDmrCVKDzus7ANPWgmT5"
accessSecret = "1au0kxES6SMId4SyfgK24abybVkNF5GF9saqnm84PC5ej"
options(httr_oauth_cache=TRUE) # skip question appearing on console
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
tweets<-searchTwitter("#DiscoverYourPower",n = 500)
tweetDF<-twListToDF(tweets)
currentDate<-Sys.Date()
csvFileName <- paste("tweets ",currentDate,".csv",sep="")
write.csv(x = tweetDF,file = csvFileName)
getcwd()
getwd()
library(twitteR)
#http://thinktostart.com/twitter-authentification-with-r/
#See https://apps.twitter.com/
consumerKey = "nD7NY6kqO8Fi3w48xJdBG9aD1"
consumerSecret = "YX6kBnn1CCbeDM2FQick78FAPmcvlKvUPjhgDNHoB3NTAl88X5"
accessToken = "532587577-dpIxDgmOCamsGApioe9BRDmrCVKDzus7ANPWgmT5"
accessSecret = "1au0kxES6SMId4SyfgK24abybVkNF5GF9saqnm84PC5ej"
options(httr_oauth_cache=TRUE) # skip question appearing on console
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
tweets<-searchTwitter("#DiscoverYourPower",n = 500)
tweetDF<-twListToDF(tweets)
currentDate<-Sys.Date()
csvFileName <- paste("tweets ",currentDate,".csv",sep="")
write.csv(x = tweetDF,file = csvFileName)
tweetMaster<-file.choose()
tweetData<-read.csv(tweetMaster)
library(dplyr)
library(tidyr)
topTweeter<-tweetData%>%
group_by(screenName)%>%
summarise(count=n())%>%
arrange(desc(count))
write.csv(x = topTweeter,file = "topTweeter.csv")
topRetweeter<-tweetData%>%
group_by(screenName)%>%
summarise(totalretweets=sum(retweetCount))%>%
arrange(desc(totalretweets))
write.csv(x = topRetweeter,file = "topRetweeter.csv")
tweetByDayDF<-tweetData
tweetByDay<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetByDay.csv")
library(ggplot2)
plotData<-read.csv("tweetByDay.csv")
plotData<-select(plotData,tweetDate,dayCount)
ggplot(data = plotData, aes(x = tweetDate, y=dayCount))+geom_bar(stat = "identity")
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet=='TRUE')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDayTWEETnotRETWEET,file = "tweetNOTRETWEETByDay.csv")
library(ggplot2)
plotData<-read.csv("tweetNOTRETWEETByDay.csv")
plotData<-select(plotData,tweetDate,dayCount)
ggplot(data = plotData, aes(x = tweetDate, y=dayCount))+geom_bar(stat = "identity")
library(twitteR)
#http://thinktostart.com/twitter-authentification-with-r/
#See https://apps.twitter.com/
consumerKey = "nD7NY6kqO8Fi3w48xJdBG9aD1"
consumerSecret = "YX6kBnn1CCbeDM2FQick78FAPmcvlKvUPjhgDNHoB3NTAl88X5"
accessToken = "532587577-dpIxDgmOCamsGApioe9BRDmrCVKDzus7ANPWgmT5"
accessSecret = "1au0kxES6SMId4SyfgK24abybVkNF5GF9saqnm84PC5ej"
options(httr_oauth_cache=TRUE) # skip question appearing on console
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
tweets<-searchTwitter("#DiscoverYourPower",n = 500)
tweetDF<-twListToDF(tweets)
currentDate<-Sys.Date()
csvFileName <- paste("tweets ",currentDate,".csv",sep="")
write.csv(x = tweetDF,file = csvFileName)
library(rattle)
data <- read.csv("C:/Users/joet/Desktop/[CURRENT]/GitHub/Kaggle/Kobe Bryant Shots/data.csv")
View(data)
summary(data)
shots<-data
mean(shots$shot_made_flag)
mean(shots$shot_made_flag, na.rm = TRUE)
library(dplyr)
library(ggplot2)
#Set working directory
#setwd("~/Desktop/Kobe Bryant Shots")
#Read data file
rawData<-read.csv(file = "data.csv")
#Extract train and test data sets
trainData<-rawData%>%
filter(!is.na(shot_made_flag))
testData<-rawData%>%
filter(is.na(shot_made_flag))
#Check for most common outcome of shot in training set
table(trainData$shot_made_flag)
prop.table(table(trainData$shot_made_flag))
setwd("C:/Users/joet/Desktop/[CURRENT]/GitHub/Kaggle/Kobe Bryant Shots")
#Set working directory
setwd("C:/Users/joet/Desktop/[CURRENT]/GitHub/Kaggle/Kobe Bryant Shots")
#Read data file
rawData<-read.csv(file = "data.csv")
#Extract train and test data sets
trainData<-rawData%>%
filter(!is.na(shot_made_flag))
testData<-rawData%>%
filter(is.na(shot_made_flag))
#Check for most common outcome of shot in training set
table(trainData$shot_made_flag)
prop.table(table(trainData$shot_made_flag))
testData$shot_made_flag = mean(trainData$shot_made_flag)
View(testData)
#Create csv submission
submit4<- data.frame(shot_id = testData$shot_id, shot_made_flag=testData$shot_made_flag)
write.csv(submit4, file = "allShotsmean.csv", row.names = FALSE)
install.packages('rattle')
install.packages("rattle")
library(rattle)
print('test')
View(testData)
View(testData)
library(rattle)
rattle()
library(dplyr)
library(ggplot2)
library(randomForest)
#Set working directory
setwd("C:/Users/joet/Desktop/[CURRENT]/GitHub/Kaggle/Kobe Bryant Shots")
set.seed(2012)
#Read data file
rawData<-read.csv(file = "data.csv")
#Prepare data file
rawData$action_type<-unclass(rawData$action_type)
rawData$game_date<-unclass(rawData$game_date)
rawData$matchup<-substr(rawData$matchup,5,5)
rawData$matchup[rawData$matchup=='@']<-"Away"
rawData$matchup[rawData$matchup=='v']<-"Home"
rawData$matchup<-as.factor(rawData$matchup)
rawDataPreped<-rawData%>%
select(-game_event_id,-game_id,-team_id,-team_name,-game_date)
names(rawDataPreped)
#Select final columns
rawDataPreped<-rawData%>%
select(-game_event_id,-game_id,-team_id,-team_name,-game_date)
#Extract train and test data sets
trainData<-rawDataPreped%>%
filter(!is.na(shot_made_flag))
#Extract train and test data sets
trainData<-rawDataPreped%>%
filter(!is.na(shot_made_flag))
#Extract shot id and then remove
trainShotId<-trainData$shot_id
trainData<-trainData%>%
select(-shot_id)
testData<-rawDataPreped%>%
filter(is.na(shot_made_flag))
#Extract shot id and then remove
testShotId<-testData$shot_id
testData<-testData%>%
select(-shot_id)
#Build forest with all variables
fit<-randomForest(shot_made_flag ~ .,
data=trainData, importance = TRUE, ntree = 2000)
#Check MSE and importance of variables
fit
varImpPlot(fit)
#Write prediction for submission
prediction <- predict(fit, testData)
testData$shot_made_flag = prediction
submit <- data.frame(shot_id = testShotId, shot_made_flag=testData$shot_made_flag)
View(submit)
write.csv(submit, file = "Model 9 - RandomForest3.csv", row.names = FALSE)
trainingInput<-trainData%>%select(-shot_made_flag)
trainingOutput<-trainData$shot_made_flag
result <- rfcv(trainingInput, trainingOutput, cv.fold=10)
View(trainData)
warnings()
result
result
importance(fit)
importance(fit, sort=TRUE)
importwhich.min(fit$mse)
which.min(fit$mse)
str(result)
library(dplyr)
library(ggplot2)
library(randomForest)
#Set working directory
setwd("C:/Users/joet/Desktop/[CURRENT]/GitHub/Kaggle/Kobe Bryant Shots")
set.seed(2012)
#Read data file
rawData<-read.csv(file = "data.csv")
#Prepare data file
rawData$action_type<-unclass(rawData$action_type)
rawData$game_date<-unclass(rawData$game_date)
rawData$matchup<-substr(rawData$matchup,5,5)
rawData$matchup[rawData$matchup=='@']<-"Away"
rawData$matchup[rawData$matchup=='v']<-"Home"
rawData$matchup<-as.factor(rawData$matchup)
#Select final columns
rawDataPreped<-rawData%>%
select(-game_event_id,-game_id,-team_id,-team_name,-game_date)
#Extract train and test data sets
trainData<-rawDataPreped%>%
filter(!is.na(shot_made_flag))
#Extract shot id and then remove
trainShotId<-trainData$shot_id
trainData<-trainData%>%
select(-shot_id)
testData<-rawDataPreped%>%
filter(is.na(shot_made_flag))
#Extract shot id and then remove
testShotId<-testData$shot_id
testData<-testData%>%
select(-shot_id)
#Build forest with all variables
fit<-randomForest(shot_made_flag ~ action_type + combined_shot_type,
data=trainData, importance = TRUE, ntree = 2000)
fit
varImpPlot(fit)
importance(fit)
which.min(fit$mse)
which.min(fit$mse)
prediction <- predict(fit, testData)
testData$shot_made_flag = prediction
submit <- data.frame(shot_id = testShotId, shot_made_flag=testData$shot_made_flag)
write.csv(submit, file = "Model 10 - RandomForest.csv", row.names = FALSE)
library(dplyr)
library(ggplot2)
library(randomForest)
#Set working directory
setwd("C:/Users/joet/Desktop/[CURRENT]/GitHub/Kaggle/Kobe Bryant Shots")
set.seed(2012)
#Read data file
rawData<-read.csv(file = "data.csv")
#Prepare data file
rawData$action_type<-unclass(rawData$action_type)
rawData$game_date<-unclass(rawData$game_date)
rawData$matchup<-substr(rawData$matchup,5,5)
rawData$matchup[rawData$matchup=='@']<-"Away"
rawData$matchup[rawData$matchup=='v']<-"Home"
rawData$matchup<-as.factor(rawData$matchup)
#Select final columns
rawDataPreped<-rawData%>%
select(-game_event_id,-game_id,-team_id,-team_name,-game_date)
#Extract train and test data sets
trainData<-rawDataPreped%>%
filter(!is.na(shot_made_flag))
#Extract shot id and then remove
trainShotId<-trainData$shot_id
trainData<-trainData%>%
select(-shot_id)
testData<-rawDataPreped%>%
filter(is.na(shot_made_flag))
#Extract shot id and then remove
testShotId<-testData$shot_id
testData<-testData%>%
select(-shot_id)
19/3
#Build forest with all variables
fit<-randomForest(shot_made_flag ~ action_type + combined_shot_type,
data=trainData, importance = TRUE, ntree = 2000, mtry = 8)
#Check MSE and importance of variables
fit
varImpPlot(fit)
importance(fit)
which.min(fit$mse)
prediction <- predict(fit, testData)
testData$shot_made_flag = prediction
submit <- data.frame(shot_id = testShotId, shot_made_flag=testData$shot_made_flag)
write.csv(submit, file = "Model 11 - RandomForest.csv", row.names = FALSE)
fit<-randomForest(shot_made_flag ~ action_type + combined_shot_type,
data=trainData, importance = TRUE, ntree = 2000, mtry = 10)
fit
fit<-randomForest(shot_made_flag ~ action_type + combined_shot_type,
data=trainData, importance = TRUE, ntree = 2000, mtry = 4)
importance(fit)
library(dplyr)
library(ggplot2)
library(randomForest)
#Set working directory
setwd("C:/Users/joet/Desktop/[CURRENT]/GitHub/Kaggle/Kobe Bryant Shots")
set.seed(2012)
#Read data file
rawData<-read.csv(file = "data.csv")
#Prepare data file
rawData$action_type<-unclass(rawData$action_type)
rawData$game_date<-unclass(rawData$game_date)
rawData$matchup<-substr(rawData$matchup,5,5)
rawData$matchup[rawData$matchup=='@']<-"Away"
rawData$matchup[rawData$matchup=='v']<-"Home"
rawData$matchup<-as.factor(rawData$matchup)
#Select final columns
rawDataPreped<-rawData%>%
select(-game_event_id,-game_id,-team_id,-team_name,-game_date)
#Extract train and test data sets
trainData<-rawDataPreped%>%
filter(!is.na(shot_made_flag))
#Extract shot id and then remove
trainShotId<-trainData$shot_id
trainData<-trainData%>%
select(-shot_id)
testData<-rawDataPreped%>%
filter(is.na(shot_made_flag))
#Extract shot id and then remove
testShotId<-testData$shot_id
testData<-testData%>%
select(-shot_id)
#Build forest with all variables
fit<-randomForest(shot_made_flag ~ action_type + combined_shot_type,
data=trainData, importance = TRUE, ntree = 2000, mtry = 10)
#Check MSE and importance of variables
fit
varImpPlot(fit)
importance(fit)
which.min(fit$mse)
#trainingInput<-trainData%>%select(-shot_made_flag)
#trainingOutput<-trainData$shot_made_flag
#result <- rfcv(trainingInput, trainingOutput, cv.fold=10)
#Run prediction
prediction <- predict(fit, testData)
testData$shot_made_flag = prediction
#RMSE.forest<-sqrt(mean((prediction-testData$shot_made_flag)^2))
#RMSE.forest
#MAE.forest<-mean(abs(prediction-testData$shot_made_flag))
#MAE.forest
#Write prediction for submission
submit <- data.frame(shot_id = testShotId, shot_made_flag=testData$shot_made_flag)
write.csv(submit, file = "Model 12 - RandomForest.csv", row.names = FALSE)

library(twitteR)
#http://thinktostart.com/twitter-authentification-with-r/
#See https://apps.twitter.com/
consumerKey = "nD7NY6kqO8Fi3w48xJdBG9aD1"
consumerSecret = "YX6kBnn1CCbeDM2FQick78FAPmcvlKvUPjhgDNHoB3NTAl88X5"
accessToken = "532587577-dpIxDgmOCamsGApioe9BRDmrCVKDzus7ANPWgmT5"
accessSecret = "1au0kxES6SMId4SyfgK24abybVkNF5GF9saqnm84PC5ej"
options(httr_oauth_cache=TRUE) # skip question appearing on console
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
tweets<-searchTwitter("#DiscoverYourPower",n = 500)
currentDate<-Sys.Date()
tweetDF<-twListToDF(tweets)
currentDate<-Sys.Date()
csvFileName <- paste("tweets",currentDate,".csv",sep="")
csvFileName <- paste("tweets ",currentDate,".csv",sep="")
write.csv(x = tweetDF,file = csvFileName)
library(dplyr)
topTweeter<-tweetDF%>%
group_by(screenName)%>%
summarise(count=n())%>%
arrange(desc(count))
write.csv(x = topTweeter,file = "topTweeter.csv")
topRetweeter<-tweetDF%>%
group_by(screenName)%>%
summarise(totalretweets=sum(retweetCount))%>%
arrange(desc(totalretweets))
write.csv(x = topRetweeter,file = "topRetweeter.csv")
View(topRetweeter)
View(topRetweeter)
View(topTweeter)
library(dplyr)
tweetMaster<-file.choose
tweetMaster<-file.choose()
library(dplyr)
tweetMaster<-file.choose()
tweetData<-read.csv(tweetMaster)
View(tweetData)
library(dplyr)
library(tidyr)
topTweeter<-tweetDF%>%
group_by(screenName)%>%
summarise(count=n())%>%
arrange(desc(count))
write.csv(x = topTweeter,file = "topTweeter.csv")
topRetweeter<-tweetDF%>%
group_by(screenName)%>%
summarise(totalretweets=sum(retweetCount))%>%
arrange(desc(totalretweets))
write.csv(x = topRetweeter,file = "topRetweeter.csv")
topTweeter<-tweetData%>%
group_by(screenName)%>%
summarise(count=n())%>%
arrange(desc(count))
write.csv(x = topTweeter,file = "topTweeter.csv")
View(topTweeter)
View(tweetData)
tweetByDayDF<-tweetData
tweetByDay<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetByDay.csv")
View(tweetByDayDF)
View(tweetByDay)
View(tweetData)
tweetMaster<-file.choose()
tweetData<-read.csv(tweetMaster)
library(dplyr)
library(tidyr)
topTweeter<-tweetData%>%
group_by(screenName)%>%
summarise(count=n())%>%
arrange(desc(count))
write.csv(x = topTweeter,file = "topTweeter.csv")
View(topTweeter)
topRetweeter<-tweetData%>%
group_by(screenName)%>%
summarise(totalretweets=sum(retweetCount))%>%
arrange(desc(totalretweets))
write.csv(x = topRetweeter,file = "topRetweeter.csv")
tweetByDayDF<-tweetData
tweetByDay<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetByDay.csv")
library(ggplot2)
plotData<-read.csv("tweetByDay.csv")
plotData<-select(plotData,tweetDate,dayCount)
ggplot(data = plotData, aes(x = tweetDate, y=dayCount))+geom_bar(stat = "identity")
View(plotData)
View(tweetData)
View(topTweeter)
View(topTweeter)
View(tweetByDay)
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet='True')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetNOTRETWEETByDay.csv")
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet='TRUE')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet=='TRUE')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
View(tweetByDayTWEETnotRETWEET)
View(tweetByDayDF)
write.csv(x = tweetByDay,file = "tweetNOTRETWEETByDay.csv")
library(ggplot2)
plotData<-read.csv("tweetNOTRETWEETByDay.csv")
plotData<-select(plotData,tweetDate,dayCount)
ggplot(data = plotData, aes(x = tweetDate, y=dayCount))+geom_bar(stat = "identity")
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet=='TRUE')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetNOTRETWEETByDay.csv")
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet=='TRUE')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDayTWEETnotRETWEET,file = "tweetNOTRETWEETByDay.csv")
library(ggplot2)
plotData<-read.csv("tweetNOTRETWEETByDay.csv")
plotData<-select(plotData,tweetDate,dayCount)
ggplot(data = plotData, aes(x = tweetDate, y=dayCount))+geom_bar(stat = "identity")
library(twitteR)
#http://thinktostart.com/twitter-authentification-with-r/
#See https://apps.twitter.com/
consumerKey = "nD7NY6kqO8Fi3w48xJdBG9aD1"
consumerSecret = "YX6kBnn1CCbeDM2FQick78FAPmcvlKvUPjhgDNHoB3NTAl88X5"
accessToken = "532587577-dpIxDgmOCamsGApioe9BRDmrCVKDzus7ANPWgmT5"
accessSecret = "1au0kxES6SMId4SyfgK24abybVkNF5GF9saqnm84PC5ej"
options(httr_oauth_cache=TRUE) # skip question appearing on console
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
tweets<-searchTwitter("#DiscoverYourPower",n = 500)
tweetDF<-twListToDF(tweets)
currentDate<-Sys.Date()
csvFileName <- paste("tweets ",currentDate,".csv",sep="")
write.csv(x = tweetDF,file = csvFileName)
tweetMaster<-file.choose()
tweetData<-read.csv(tweetMaster)
library(dplyr)
library(tidyr)
topTweeter<-tweetData%>%
group_by(screenName)%>%
summarise(count=n())%>%
arrange(desc(count))
write.csv(x = topTweeter,file = "topTweeter.csv")
topRetweeter<-tweetData%>%
group_by(screenName)%>%
summarise(totalretweets=sum(retweetCount))%>%
arrange(desc(totalretweets))
write.csv(x = topRetweeter,file = "topRetweeter.csv")
View(topRetweeter)
View(topTweeter)
tweetByDayDF<-tweetData
tweetByDay<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetByDay.csv")
View(tweetByDay)
library(twitteR)
#http://thinktostart.com/twitter-authentification-with-r/
#See https://apps.twitter.com/
consumerKey = "nD7NY6kqO8Fi3w48xJdBG9aD1"
consumerSecret = "YX6kBnn1CCbeDM2FQick78FAPmcvlKvUPjhgDNHoB3NTAl88X5"
accessToken = "532587577-dpIxDgmOCamsGApioe9BRDmrCVKDzus7ANPWgmT5"
accessSecret = "1au0kxES6SMId4SyfgK24abybVkNF5GF9saqnm84PC5ej"
options(httr_oauth_cache=TRUE) # skip question appearing on console
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
tweets<-searchTwitter("#DiscoverYourPower",n = 500)
tweetDF<-twListToDF(tweets)
currentDate<-Sys.Date()
csvFileName <- paste("tweets ",currentDate,".csv",sep="")
write.csv(x = tweetDF,file = csvFileName)
View(tweetDF)
getwd()
library(twitteR)
#http://thinktostart.com/twitter-authentification-with-r/
#See https://apps.twitter.com/
consumerKey = "nD7NY6kqO8Fi3w48xJdBG9aD1"
consumerSecret = "YX6kBnn1CCbeDM2FQick78FAPmcvlKvUPjhgDNHoB3NTAl88X5"
accessToken = "532587577-dpIxDgmOCamsGApioe9BRDmrCVKDzus7ANPWgmT5"
accessSecret = "1au0kxES6SMId4SyfgK24abybVkNF5GF9saqnm84PC5ej"
options(httr_oauth_cache=TRUE) # skip question appearing on console
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
tweets<-searchTwitter("#DiscoverYourPower",n = 500)
tweetDF<-twListToDF(tweets)
currentDate<-Sys.Date()
csvFileName <- paste("tweets ",currentDate,".csv",sep="")
write.csv(x = tweetDF,file = csvFileName)
getcwd()
getwd()
library(twitteR)
#http://thinktostart.com/twitter-authentification-with-r/
#See https://apps.twitter.com/
consumerKey = "nD7NY6kqO8Fi3w48xJdBG9aD1"
consumerSecret = "YX6kBnn1CCbeDM2FQick78FAPmcvlKvUPjhgDNHoB3NTAl88X5"
accessToken = "532587577-dpIxDgmOCamsGApioe9BRDmrCVKDzus7ANPWgmT5"
accessSecret = "1au0kxES6SMId4SyfgK24abybVkNF5GF9saqnm84PC5ej"
options(httr_oauth_cache=TRUE) # skip question appearing on console
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
tweets<-searchTwitter("#DiscoverYourPower",n = 500)
tweetDF<-twListToDF(tweets)
currentDate<-Sys.Date()
csvFileName <- paste("tweets ",currentDate,".csv",sep="")
write.csv(x = tweetDF,file = csvFileName)
tweetMaster<-file.choose()
tweetData<-read.csv(tweetMaster)
library(dplyr)
library(tidyr)
topTweeter<-tweetData%>%
group_by(screenName)%>%
summarise(count=n())%>%
arrange(desc(count))
write.csv(x = topTweeter,file = "topTweeter.csv")
topRetweeter<-tweetData%>%
group_by(screenName)%>%
summarise(totalretweets=sum(retweetCount))%>%
arrange(desc(totalretweets))
write.csv(x = topRetweeter,file = "topRetweeter.csv")
tweetByDayDF<-tweetData
tweetByDay<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDay,file = "tweetByDay.csv")
library(ggplot2)
plotData<-read.csv("tweetByDay.csv")
plotData<-select(plotData,tweetDate,dayCount)
ggplot(data = plotData, aes(x = tweetDate, y=dayCount))+geom_bar(stat = "identity")
tweetByDayTWEETnotRETWEET<-tweetByDayDF%>%
separate(created, into = c("tweetDate", "time"), sep = " ")%>%
filter(isRetweet=='TRUE')%>%
group_by(tweetDate)%>%
summarise(dayCount=n())%>%
arrange(tweetDate)
write.csv(x = tweetByDayTWEETnotRETWEET,file = "tweetNOTRETWEETByDay.csv")
library(ggplot2)
plotData<-read.csv("tweetNOTRETWEETByDay.csv")
plotData<-select(plotData,tweetDate,dayCount)
ggplot(data = plotData, aes(x = tweetDate, y=dayCount))+geom_bar(stat = "identity")
library(twitteR)
#http://thinktostart.com/twitter-authentification-with-r/
#See https://apps.twitter.com/
consumerKey = "nD7NY6kqO8Fi3w48xJdBG9aD1"
consumerSecret = "YX6kBnn1CCbeDM2FQick78FAPmcvlKvUPjhgDNHoB3NTAl88X5"
accessToken = "532587577-dpIxDgmOCamsGApioe9BRDmrCVKDzus7ANPWgmT5"
accessSecret = "1au0kxES6SMId4SyfgK24abybVkNF5GF9saqnm84PC5ej"
options(httr_oauth_cache=TRUE) # skip question appearing on console
setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret,
access_token = accessToken, access_secret = accessSecret)
tweets<-searchTwitter("#DiscoverYourPower",n = 500)
tweetDF<-twListToDF(tweets)
currentDate<-Sys.Date()
csvFileName <- paste("tweets ",currentDate,".csv",sep="")
write.csv(x = tweetDF,file = csvFileName)
library(rattle)
library(dplyr)
#Set working directory
setwd("C:/Users/joet/Desktop/[CURRENT]/GitHub/Kaggle/Kobe Bryant Shots")
set.seed(2012)
#Read data file
rawData<-read.csv(file = "data.csv")
action_type_rare <- data %>%
select(action_type) %>%
group_by(action_type) %>%
summarise(count=n()) %>%
filter(count < 30) %>%
select(action_type) %>%
droplevels
action_type_rare <- rawData %>%
select(action_type) %>%
group_by(action_type) %>%
summarise(count=n()) %>%
filter(count < 30) %>%
select(action_type) %>%
droplevels
View(action_type_rare)
action_type_rare <- action_type_rare$action_type
action_type <- rawData$action_type
action_type_2 <- factor(ifelse(action_type %in% action_type_rare,0,action_type), labels=c('Rare Shot',levels(action_type)[!levels(action_type) %in% levels(action_type_rare)]))
data <- cbind(rawData,action_type_2)
View(data)
which(data$action_type_2=="Rare Shot")
library(dplyr)
#Set working directory
setwd("C:/Users/joet/Desktop/[CURRENT]/GitHub/Kaggle/Kobe Bryant Shots")
set.seed(2012)
#Read data file
rawData<-read.csv(file = "data.csv")
#summarize action_type, remove levels where less than 30 shots occurred
action_type_rare <- rawData %>%
select(action_type) %>%
group_by(action_type) %>%
summarise(count=n()) %>%
filter(count < 30) %>%
select(action_type) %>%
droplevels
#store as vector
action_type_rare <- action_type_rare$action_type
#grab action_type vector
action_type <- rawData$action_type
#create new factor with fewer levels and 'Rare Shot' level
action_type_2 <- factor(ifelse(action_type %in% action_type_rare,0,action_type), labels=c('Rare Shot',levels(action_type)[!levels(action_type) %in% levels(action_type_rare)]))
#add new level to data
rawData <- cbind(rawData,action_type_2)
rawData$matchup<-substr(rawData$matchup,5,5)
rawData$matchup[rawData$matchup=='@']<-"Away"
rawData$matchup[rawData$matchup=='v']<-"Home"
rawData$matchup<-as.factor(rawData$matchup)
rawData$timeLeft<-(rawData$minutes_remaining*60)+rawData$seconds_remaining
rawData$timeElapsed<-(12*60)-rawData$time
#Select final columns
rawDataPreped<-rawData%>%
select(-game_event_id,-game_id,-team_id,-team_name,-game_date)
#Extract train and test data sets
trainData<-rawDataPreped%>%
filter(!is.na(shot_made_flag))
#Extract shot id and then remove
trainShotId<-trainData$shot_id
trainData<-trainData%>%
select(-shot_id)
testData<-rawDataPreped%>%
filter(is.na(shot_made_flag))
#Extract shot id and then remove
testShotId<-testData$shot_id
testData<-testData%>%
select(-shot_id)
#Extract shot id and then remove
trainShotId<-trainData$shot_id
trainData<-trainData%>%
select(-shot_id, -action_type, -minutes_remaining, -seconds_remaining)
#Extract train and test data sets
trainData<-rawDataPreped%>%
filter(!is.na(shot_made_flag))
#Extract shot id and then remove
trainShotId<-trainData$shot_id
trainData<-trainData%>%
select(-shot_id, -action_type, -minutes_remaining, -seconds_remaining)
testData<-rawDataPreped%>%
filter(is.na(shot_made_flag))
#Extract shot id and then remove
testShotId<-testData$shot_id
testData<-testData%>%
select(-shot_id, -action_type, -minutes_remaining, -seconds_remaining)
#Build forest with all variables
fit<-randomForest(shot_made_flag ~ .,
data=trainData, importance = TRUE, ntree = 2000)
library(randomForest)
#Build forest with all variables
fit<-randomForest(shot_made_flag ~ .,
data=trainData, importance = TRUE, ntree = 2000)
fit
summary(fit)
varImpPlot(fit)
importance(fit)
which.min(fit$mse)
#Run prediction
prediction <- predict(fit, testData)
testData$shot_made_flag = prediction
#Write prediction for submission
submit <- data.frame(shot_id = testShotId, shot_made_flag=testData$shot_made_flag)
write.csv(submit, file = "Model 17 - RandomForest (action_type2 time elapsed timeLeft and all).csv", row.names = FALSE)
summary(rawDataPreped)
summary(rawDataPreped$period)
which(rawDataPreped>4)
which(rawDataPreped$period>4)
which(rawDataPreped$period==5)
View(rawDataPreped)
which(rawDataPreped$period==6)
library(dplyr)
library(randomForest)
#Set working directory
setwd("C:/Users/joet/Desktop/[CURRENT]/GitHub/Kaggle/Kobe Bryant Shots")
set.seed(2012)
#Read data file
rawData<-read.csv(file = "data.csv")
#summarize action_type, remove levels where less than 30 shots occurred
action_type_rare <- rawData %>%
select(action_type) %>%
group_by(action_type) %>%
summarise(count=n()) %>%
filter(count < 30) %>%
select(action_type) %>%
droplevels
#store as vector
action_type_rare <- action_type_rare$action_type
#grab action_type vector
action_type <- rawData$action_type
#create new factor with fewer levels and 'Rare Shot' level
action_type_2 <- factor(ifelse(action_type %in% action_type_rare,0,action_type), labels=c('Rare Shot',levels(action_type)[!levels(action_type) %in% levels(action_type_rare)]))
#add new level to data
rawData <- cbind(rawData,action_type_2)
rawData$matchup<-substr(rawData$matchup,5,5)
rawData$matchup[rawData$matchup=='@']<-"Away"
rawData$matchup[rawData$matchup=='v']<-"Home"
rawData$matchup<-as.factor(rawData$matchup)
rawData$timeLeft<-(rawData$minutes_remaining*60)+rawData$seconds_remaining
rawData$timeElapsed<-(12*60)-rawData$time
#Select final columns
rawDataPreped<-rawData%>%
select(-game_event_id,-game_id,-team_id,-team_name,-game_date)
#Extract train and test data sets
trainData<-rawDataPreped%>%
filter(!is.na(shot_made_flag))
#Extract shot id and then remove
trainShotId<-trainData$shot_id
trainData<-trainData%>%
select(-shot_id, -action_type, -minutes_remaining, -seconds_remaining)
testData<-rawDataPreped%>%
filter(is.na(shot_made_flag))
#Extract shot id and then remove
testShotId<-testData$shot_id
testData<-testData%>%
select(-shot_id, -action_type, -minutes_remaining, -seconds_remaining)
#Build forest with all variables
fit<-randomForest(shot_made_flag ~ action_type_2,timeElapsed,
data=trainData, importance = TRUE, ntree = 2000)
#Check MSE and importance of variables
fit
varImpPlot(fit)
importance(fit)
which.min(fit$mse)
#Run prediction
prediction <- predict(fit, testData)
testData$shot_made_flag = prediction
#Write prediction for submission
submit <- data.frame(shot_id = testShotId, shot_made_flag=testData$shot_made_flag)
write.csv(submit, file = "Model 18 - RandomForest (action_type2 time elapsed).csv", row.names = FALSE)
library(dplyr)
library(randomForest)
#Set working directory
setwd("C:/Users/joet/Desktop/[CURRENT]/GitHub/Kaggle/Kobe Bryant Shots")
set.seed(2012)
#Read data file
rawData<-read.csv(file = "data.csv")
#summarize action_type, remove levels where less than 30 shots occurred
action_type_rare <- rawData %>%
select(action_type) %>%
group_by(action_type) %>%
summarise(count=n()) %>%
filter(count < 30) %>%
select(action_type) %>%
droplevels
#store as vector
action_type_rare <- action_type_rare$action_type
#grab action_type vector
action_type <- rawData$action_type
#create new factor with fewer levels and 'Rare Shot' level
action_type_2 <- factor(ifelse(action_type %in% action_type_rare,0,action_type), labels=c('Rare Shot',levels(action_type)[!levels(action_type) %in% levels(action_type_rare)]))
#add new level to data
rawData <- cbind(rawData,action_type_2)
rawData$matchup<-substr(rawData$matchup,5,5)
rawData$matchup[rawData$matchup=='@']<-"Away"
rawData$matchup[rawData$matchup=='v']<-"Home"
rawData$matchup<-as.factor(rawData$matchup)
rawData$timeLeft<-(rawData$minutes_remaining*60)+rawData$seconds_remaining
rawData$timeElapsed<-(12*60)-rawData$time
#Select final columns
rawDataPreped<-rawData%>%
select(-game_event_id,-game_id,-team_id,-team_name,-game_date)
#Extract train and test data sets
trainData<-rawDataPreped%>%
filter(!is.na(shot_made_flag))
#Extract shot id and then remove
trainShotId<-trainData$shot_id
trainData<-trainData%>%
select(-shot_id, -action_type, -minutes_remaining, -seconds_remaining)
testData<-rawDataPreped%>%
filter(is.na(shot_made_flag))
#Extract shot id and then remove
testShotId<-testData$shot_id
testData<-testData%>%
select(-shot_id, -action_type, -minutes_remaining, -seconds_remaining)
#Build forest with all variables
fit<-randomForest(shot_made_flag ~ action_type_2+ timeElapsed,
data=trainData, importance = TRUE, ntree = 2000)
#Check MSE and importance of variables
fit
varImpPlot(fit)
importance(fit)
#Run prediction
prediction <- predict(fit, testData)
testData$shot_made_flag = prediction
#Write prediction for submission
submit <- data.frame(shot_id = testShotId, shot_made_flag=testData$shot_made_flag)
write.csv(submit, file = "Model 18 - RandomForest (action_type2 time elapsed).csv", row.names = FALSE)
